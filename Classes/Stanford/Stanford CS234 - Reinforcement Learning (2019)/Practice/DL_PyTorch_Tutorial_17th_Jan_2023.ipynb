{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Imports**"
      ],
      "metadata": {
        "id": "kVrB3bXfiBgW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BZMYdNa8tW1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining a torch tensor**"
      ],
      "metadata": {
        "id": "JpG2pR6GiTVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state = torch.tensor([1,2,3]) # long by default\n",
        "state"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brc1tqmFiA5e",
        "outputId": "60af8b32-1345-46ab-8b72-d724ba88fc60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Other tensor types\n",
        "state = torch.tensor([1,2,3], dtype=torch.float)\n",
        "state"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2-zlsu8isdf",
        "outputId": "935a9c39-044d-449f-b6b1-3ce52e40d80c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-dimenstional tensors\n",
        "state = torch.Tensor([[1,2,3], [4,5,6], [7,8,9]]) # float32 by default\n",
        "state"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHH6SkRdi16d",
        "outputId": "cefa51d6-5e87-4362-dcc4-daa3bbe833fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 6.],\n",
              "        [7., 8., 9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A couple more useful torch functions to initialize tensors\n",
        "print(torch.zeros((2,2)))\n",
        "print(torch.ones((3,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEEOShKOm1my",
        "outputId": "ab013e22-8ebd-4162-eec1-fff5946042d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.]])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Some useful tensor properties**"
      ],
      "metadata": {
        "id": "TDxQByS1iZqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(state)\n",
        "print(state.dtype) # the type of elements in the tensor, eg: long, float32, etc.\n",
        "print(state.shape) # the shape of the tensor\n",
        "print(state.device) # the device the tensor is on: CPU or GPU\n",
        "print(state.grad) # the gradient of the tensor, more on this later"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onv5dRXEiYni",
        "outputId": "24a4b2c6-efb8-4cda-f09d-f1826e08961c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.],\n",
            "        [7., 8., 9.]])\n",
            "torch.float32\n",
            "torch.Size([3, 3])\n",
            "cpu\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Side note: How to check if I have a GPU?**"
      ],
      "metadata": {
        "id": "-c4lDYTGjgjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Not using a GPU right now\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tz4_svYGifnm",
        "outputId": "355f1a15-807a-4224-de8a-430d6de4187f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Useful tensor operations**"
      ],
      "metadata": {
        "id": "E8BYqWNRjufH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(state.sum()) # Also torch.sum(state)\n",
        "print(state.mean()) # Also torch.mean(state)\n",
        "print(state.max()) # Also torch.max(state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6Nvp8yGjnY1",
        "outputId": "f51c259f-39ab-46e7-b6a5-a24f56cf2ea7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(45.)\n",
            "tensor(5.)\n",
            "tensor(9.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also do these operations across specific dimensions. Here is an example with `sum` but you can do the same things with other operations like `max` and `mean` as well."
      ],
      "metadata": {
        "id": "UlJ7Lf8vlQef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# summing with dim=0 collapses 0th dimension aka row dimension and sums the columns\n",
        "print(state.sum(dim=0)) \n",
        "# summing with dim=1 collapses the 1st dimension aka column dimension and sums the rows\n",
        "print(state.sum(dim=1)) \n",
        "# summing with dim=-1 collapses the last dimension aka column dimension and sums the rows\n",
        "print(state.sum(dim=-1)) \n",
        "# Here is a more telling example\n",
        "print(torch.ones((3,4,5)).sum(-1).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gENhh_xlWJs",
        "outputId": "4accb84a-9c3b-4865-ff38-a51724b8ba70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([12., 15., 18.])\n",
            "tensor([ 6., 15., 24.])\n",
            "tensor([ 6., 15., 24.])\n",
            "torch.Size([3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can add and subtract tensors and multiply them as you do with `numpy` arrays. You can also do broadcast operations as you would with numpy arrays"
      ],
      "metadata": {
        "id": "2pVphnV5k5vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(state * 2) # every element is multiplied by 2\n",
        "print(\"*****************\")\n",
        "print(state + 2) # 2 is added to every element"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQfd4m2Ekzbj",
        "outputId": "9f004c4a-7a76-4363-dc70-7a54a9009001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.,  4.,  6.],\n",
            "        [ 8., 10., 12.],\n",
            "        [14., 16., 18.]])\n",
            "*****************\n",
            "tensor([[ 3.,  4.,  5.],\n",
            "        [ 6.,  7.,  8.],\n",
            "        [ 9., 10., 11.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Element-wise multiplication and matrix multiplication**"
      ],
      "metadata": {
        "id": "dcYhm0H3nhAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.Tensor([1,2,3]) # 1x3\n",
        "x2 = torch.Tensor([4,5,6]) # 1x3\n",
        "x3 = torch.ones((3,3)) # 3x3\n",
        "\n",
        "print(x1 * x2) # element-wise multiplication\n",
        "print(x1.dot(x2)) # vector dot product\n",
        "print(x1.matmul(x3)) # matrix multiplication"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN9H0U3ZnnXo",
        "outputId": "119f3b8f-91c8-44f8-a5f6-4f5ba13ed091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 4., 10., 18.])\n",
            "tensor(32.)\n",
            "tensor([6., 6., 6.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reshaping Torch tensors**"
      ],
      "metadata": {
        "id": "lG8B7uRjog0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones((3,4,5))\n",
        "y = torch.ones((2,3))\n",
        "\n",
        "print(x.reshape(20,3).shape)\n",
        "print(x.reshape(3, -1).shape) # torch infers what should come in the -1 position\n",
        "print(x.reshape(5,2,-1).shape)\n",
        "print(y.T.shape) # NOT the same as y.reshape(3,2)\n",
        "print(x.transpose(-1,1).shape) # allows you to swapaxes in multi-dimensional tensors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--A01Nc0oRcZ",
        "outputId": "0b374415-03c1-4cde-db92-b1971a735ddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20, 3])\n",
            "torch.Size([3, 20])\n",
            "torch.Size([5, 2, 6])\n",
            "torch.Size([3, 2])\n",
            "torch.Size([3, 5, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Some more useful methods**"
      ],
      "metadata": {
        "id": "g9kipjv3p33E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.Tensor([1,2,3,4])\n",
        "x2 = torch.Tensor([2,3,5,7])\n",
        "\n",
        "print(F.mse_loss(x1, x2)) # calculates MSE loss between x1 and x2\n",
        "print(torch.sigmoid(x1)) # applies the sigmoid function on the given tensor\n",
        "print(F.one_hot(x1.long(), 5)) # converts the tensor to one-hot\n",
        "print(F.one_hot(x1.long(), 7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDNGlkZIomxU",
        "outputId": "96fe6e54-5500-414d-95c7-5b7fa3a68df7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.7500)\n",
            "tensor([0.7311, 0.8808, 0.9526, 0.9820])\n",
            "tensor([[0, 1, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 0, 1]])\n",
            "tensor([[0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensors with gradients**"
      ],
      "metadata": {
        "id": "zHcAngX_rAAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state = torch.Tensor([[1,2,3], [4,5,6]])\n",
        "print(state.grad) # state has no gradient now\n",
        "print(state.requires_grad) # torch is not tracking the gradient either\n",
        "state.requires_grad = True # this will tell torch to track the gradient of state\n",
        "print(state.requires_grad)\n",
        "print(state.grad) # but still no gradient"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBnEUETYqfHp",
        "outputId": "20fc30c9-2280-42a5-815d-a2a70582391a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "False\n",
            "True\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target = 25 # some random target\n",
        "prediction = state.sum()\n",
        "loss = (target - prediction) **2 # by the way, ** is also a broadcast operation\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzYUnsdVsCWD",
        "outputId": "b43be1c0-ff04-445d-af00-cb082b2cbe4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(16., grad_fn=<PowBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "state.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgeaAljatB8E",
        "outputId": "ad598812-f88a-453b-9db4-33a6be1a896c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-8., -8., -8.],\n",
              "        [-8., -8., -8.]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now use this gradient to perform an update on `state` using gradient descent or any other fancy optimizer."
      ],
      "metadata": {
        "id": "558T1shHtgQz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The torch `nn` module**"
      ],
      "metadata": {
        "id": "6AW6I_SXt-P9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer1 = nn.Linear(10,5) # encapsulates a weight and a bias and is tracking gradients by default\n",
        "    self.layer2 = nn.Linear(5, 1) \n",
        "  \n",
        "  def forward(self, x):\n",
        "    out = self.layer1(x) # self.layer(x) performs w.T.matmul(x) + b\n",
        "    out = nn.ReLU()(out)\n",
        "    return self.layer2(out)"
      ],
      "metadata": {
        "id": "BsgDpBQ6tSOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel()\n",
        "print(model.layer1.weight.shape, model.layer1.bias.shape)\n",
        "input = torch.ones(4, 10) # shape is batchsize x dimension\n",
        "out = model(input) # same as model.forward(input)\n",
        "print(out)\n",
        "print(out.shape) # batchsize x output_dim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhKL05N9ulaW",
        "outputId": "ff603933-1108-4ef8-cb02-93d894e93b6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 10]) torch.Size([5])\n",
            "tensor([[-0.0836],\n",
            "        [-0.0836],\n",
            "        [-0.0836],\n",
            "        [-0.0836]], grad_fn=<AddmmBackward0>)\n",
            "torch.Size([4, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's add a simple loss function"
      ],
      "metadata": {
        "id": "3TjFxF1wwaFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = torch.tensor([0.4, 0.2, 0.99, 0.3]).reshape(-1, 1) # random target\n",
        "loss = F.mse_loss(out, target) # MSE loss\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiyCD05rvRdF",
        "outputId": "e6f2c655-b4ba-4a0d-df3a-b0cbf20d356c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.4035, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.layer1.weight, model.layer1.bias) # no gradient yet\n",
        "print(\"*************************************\")\n",
        "print(model.layer1.weight.grad, model.layer1.bias.grad) # no gradient yet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPqqJhGFxwRB",
        "outputId": "41d6c4cc-4f69-42f6-edb2-79f7ea49c8f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.1318, -0.0576, -0.3030, -0.2118,  0.2717, -0.1217,  0.0581, -0.2497,\n",
            "         -0.2116,  0.2607],\n",
            "        [ 0.2519,  0.2266, -0.0837,  0.0837,  0.0498, -0.1639,  0.1967,  0.0892,\n",
            "          0.2818,  0.2643],\n",
            "        [ 0.2002, -0.2317, -0.1012,  0.1545, -0.1425, -0.1672, -0.2687, -0.0745,\n",
            "          0.1760,  0.2588],\n",
            "        [ 0.1746, -0.2022, -0.0185,  0.2798, -0.0306,  0.2052, -0.2881,  0.0842,\n",
            "          0.2125,  0.2463],\n",
            "        [ 0.3013,  0.1859, -0.0012,  0.0886, -0.0355,  0.1531, -0.2281, -0.2515,\n",
            "          0.2611,  0.2024]], requires_grad=True) Parameter containing:\n",
            "tensor([ 0.0390,  0.1265, -0.1221, -0.0808,  0.0080], requires_grad=True)\n",
            "*************************************\n",
            "None None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we get the gradient, let's define an optimizer"
      ],
      "metadata": {
        "id": "Zkb0H-XGyC5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1) # this learning rate is extremely high for Adam btw"
      ],
      "metadata": {
        "id": "ceV9twblyG0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.zero_grad() # clears the gradients (they're cleared anyway at this point)\n",
        "loss.backward() # calculates the gradients\n",
        "print(model.layer1.weight.grad, model.layer1.bias.grad) # now we have gradients"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fp1nMUOyg0w",
        "outputId": "e2a02bfa-98a3-4421-a1f1-71abc977b14c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000],\n",
            "        [ 0.2292,  0.2292,  0.2292,  0.2292,  0.2292,  0.2292,  0.2292,  0.2292,\n",
            "          0.2292,  0.2292],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000],\n",
            "        [ 0.4020,  0.4020,  0.4020,  0.4020,  0.4020,  0.4020,  0.4020,  0.4020,\n",
            "          0.4020,  0.4020],\n",
            "        [-0.4448, -0.4448, -0.4448, -0.4448, -0.4448, -0.4448, -0.4448, -0.4448,\n",
            "         -0.4448, -0.4448]]) tensor([ 0.0000,  0.2292,  0.0000,  0.4020, -0.4448])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But we still haven't updated the weights"
      ],
      "metadata": {
        "id": "4vv1m17ay7An"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.layer1.weight, model.layer1.bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxZiQ-VSyslp",
        "outputId": "7cd3161f-66a7-4ab4-f6dd-7932539d7eeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.1318, -0.0576, -0.3030, -0.2118,  0.2717, -0.1217,  0.0581, -0.2497,\n",
            "         -0.2116,  0.2607],\n",
            "        [ 0.2519,  0.2266, -0.0837,  0.0837,  0.0498, -0.1639,  0.1967,  0.0892,\n",
            "          0.2818,  0.2643],\n",
            "        [ 0.2002, -0.2317, -0.1012,  0.1545, -0.1425, -0.1672, -0.2687, -0.0745,\n",
            "          0.1760,  0.2588],\n",
            "        [ 0.1746, -0.2022, -0.0185,  0.2798, -0.0306,  0.2052, -0.2881,  0.0842,\n",
            "          0.2125,  0.2463],\n",
            "        [ 0.3013,  0.1859, -0.0012,  0.0886, -0.0355,  0.1531, -0.2281, -0.2515,\n",
            "          0.2611,  0.2024]], requires_grad=True) Parameter containing:\n",
            "tensor([ 0.0390,  0.1265, -0.1221, -0.0808,  0.0080], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's update the weights using the optimizer, As we can see below, the weight has now been updated!"
      ],
      "metadata": {
        "id": "252ndEA5zSUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.step()\n",
        "print(model.layer1.weight, model.layer1.bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2kCjrgXzZ5B",
        "outputId": "ad26227b-d4a2-49c1-f691-e6aae72735d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.1318, -0.0576, -0.3030, -0.2118,  0.2717, -0.1217,  0.0581, -0.2497,\n",
            "         -0.2116,  0.2607],\n",
            "        [ 0.1519,  0.1266, -0.1837, -0.0163, -0.0502, -0.2639,  0.0967, -0.0108,\n",
            "          0.1818,  0.1643],\n",
            "        [ 0.2002, -0.2317, -0.1012,  0.1545, -0.1425, -0.1672, -0.2687, -0.0745,\n",
            "          0.1760,  0.2588],\n",
            "        [ 0.0746, -0.3022, -0.1185,  0.1798, -0.1306,  0.1052, -0.3881, -0.0158,\n",
            "          0.1125,  0.1463],\n",
            "        [ 0.4013,  0.2859,  0.0988,  0.1886,  0.0645,  0.2531, -0.1281, -0.1515,\n",
            "          0.3611,  0.3024]], requires_grad=True) Parameter containing:\n",
            "tensor([ 0.0390,  0.0265, -0.1221, -0.1808,  0.1080], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A general PyTorch recipe:**\n",
        "\n",
        "\n",
        "1.   Create a model class\n",
        "2.   Get your training and evaluation data\n",
        "3.   Set up an optimizer\n",
        "4.   Perform forward passes with training data\n",
        "5. `optimizer.zero_grad()`\n",
        "6. `loss.backward()`\n",
        "7. `optimizer.step()`\n",
        "8. After few steps of training, evaluate on evaluation data\n",
        "9. Repeat until loss doesn't decrease or evaluation performance starts to fall off\n",
        "\n"
      ],
      "metadata": {
        "id": "1CoIIM8Azsip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving and loading models**"
      ],
      "metadata": {
        "id": "OeZxbcJM0NVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNArbnlQKzhC",
        "outputId": "a7d150c7-f751-4613-8e56-cbdf82241004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('layer1.weight',\n",
              "              tensor([[ 0.1318, -0.0576, -0.3030, -0.2118,  0.2717, -0.1217,  0.0581, -0.2497,\n",
              "                       -0.2116,  0.2607],\n",
              "                      [ 0.1519,  0.1266, -0.1837, -0.0163, -0.0502, -0.2639,  0.0967, -0.0108,\n",
              "                        0.1818,  0.1643],\n",
              "                      [ 0.2002, -0.2317, -0.1012,  0.1545, -0.1425, -0.1672, -0.2687, -0.0745,\n",
              "                        0.1760,  0.2588],\n",
              "                      [ 0.0746, -0.3022, -0.1185,  0.1798, -0.1306,  0.1052, -0.3881, -0.0158,\n",
              "                        0.1125,  0.1463],\n",
              "                      [ 0.4013,  0.2859,  0.0988,  0.1886,  0.0645,  0.2531, -0.1281, -0.1515,\n",
              "                        0.3611,  0.3024]])),\n",
              "             ('layer1.bias',\n",
              "              tensor([ 0.0390,  0.0265, -0.1221, -0.1808,  0.1080])),\n",
              "             ('layer2.weight',\n",
              "              tensor([[-0.2829, -0.1061,  0.1022, -0.2615,  0.4999]])),\n",
              "             ('layer2.bias', tensor([0.2259]))])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pt\") # saving the model\n",
        "new_model = MyModel()\n",
        "new_model.load_state_dict(torch.load(\"model.pt\")) # loading the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvdKgw2G0RK0",
        "outputId": "2a90283b-fe45-4174-9e97-b0187c32107e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A couple more useful torch modules that you might find useful for assignments 2 and 3 are `nn.Sequential` and the `Conv2D` module. Check these out in the [PyTorch documentation](https://pytorch.org/docs/stable/index.html)!"
      ],
      "metadata": {
        "id": "yb1rs7oN1Au9"
      }
    }
  ]
}