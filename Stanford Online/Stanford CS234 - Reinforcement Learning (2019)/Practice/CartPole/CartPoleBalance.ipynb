{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Deep Reinforcement Learning to create an RL intelligent agent that can Balance a Pole on a moving Cart\n",
    "\n",
    "https://www.youtube.com/watch?v=cO5g5qLrLSo\n",
    "\n",
    "## Depencencies Needed\n",
    "- Tensorflow\n",
    "- Keras\n",
    "- Keras RL\n",
    "- OpenAI gym\n",
    "\n",
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base libs\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf libs\n",
    "import keras as k\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RL libs\n",
    "from rl.agents import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Random Env with OpenAI Gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1', render_mode=\"human\")\n",
    "states = env.observation_space.shape[0]\n",
    "print(env.observation_space.shape)\n",
    "actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States : 4 \n",
      "Actions : 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"States : {states} \\nActions : {actions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:16.0\n",
      "Episode:2 Score:19.0\n",
      "Episode:3 Score:19.0\n",
      "Episode:4 Score:15.0\n",
      "Episode:5 Score:16.0\n",
      "Episode:6 Score:37.0\n",
      "Episode:7 Score:14.0\n",
      "Episode:8 Score:89.0\n",
      "Episode:9 Score:30.0\n",
      "Episode:10 Score:10.0\n",
      "Episode:11 Score:11.0\n",
      "Episode:12 Score:18.0\n",
      "Episode:13 Score:18.0\n",
      "Episode:14 Score:18.0\n",
      "Episode:15 Score:24.0\n",
      "Episode:16 Score:25.0\n",
      "Episode:17 Score:38.0\n",
      "Episode:18 Score:21.0\n",
      "Episode:19 Score:21.0\n",
      "Episode:20 Score:29.0\n",
      "Episode:21 Score:56.0\n",
      "Episode:22 Score:13.0\n",
      "Episode:23 Score:13.0\n",
      "Episode:24 Score:30.0\n",
      "Episode:25 Score:18.0\n",
      "Episode:26 Score:21.0\n",
      "Episode:27 Score:31.0\n",
      "Episode:28 Score:13.0\n",
      "Episode:29 Score:37.0\n",
      "Episode:30 Score:68.0\n",
      "Episode:31 Score:17.0\n",
      "Episode:32 Score:23.0\n",
      "Episode:33 Score:12.0\n",
      "Episode:34 Score:18.0\n",
      "Episode:35 Score:33.0\n",
      "Episode:36 Score:10.0\n",
      "Episode:37 Score:9.0\n",
      "Episode:38 Score:9.0\n",
      "Episode:39 Score:12.0\n",
      "Episode:40 Score:25.0\n",
      "Episode:41 Score:15.0\n",
      "Episode:42 Score:16.0\n",
      "Episode:43 Score:19.0\n",
      "Episode:44 Score:54.0\n",
      "Episode:45 Score:43.0\n",
      "Episode:46 Score:26.0\n",
      "Episode:47 Score:36.0\n",
      "Episode:48 Score:14.0\n",
      "Episode:49 Score:20.0\n",
      "Episode:50 Score:16.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 50\n",
    "for episode in range(episodes):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = random.choice([0,1])\n",
    "        n_state, reward, done, truncated, info = env.step(action)\n",
    "        score += reward\n",
    "    print(f\"Episode:{episode+1} Score:{score}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(states, actions):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "    model.add(Dense(16))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(16))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(16))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(actions))\n",
    "    model.add(Activation('linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 4)                 0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                80        \n",
      "                                                                 \n",
      " activation (Activation)     (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 658\n",
      "Trainable params: 658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(states, actions)\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Keras-RL Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                80        \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 16)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 16)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 16)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 658\n",
      "Trainable params: 658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Training for 50000 steps ...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected flatten_1_input to have shape (1, 4) but got array with shape (1, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 45\u001b[0m\n\u001b[0;32m     40\u001b[0m dqn\u001b[39m.\u001b[39mcompile(Adam(learning_rate\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m), metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mmae\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     42\u001b[0m \u001b[39m# Okay, now it's time to learn something! We visualize the training here for show, but this\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[39m# slows down training quite a lot. You can always safely abort the training prematurely using\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[39m# Ctrl + C.\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m dqn\u001b[39m.\u001b[39;49mfit(env, nb_steps\u001b[39m=\u001b[39;49m\u001b[39m50000\u001b[39;49m, visualize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[0;32m     47\u001b[0m \u001b[39m# After training is done, we save the final weights.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m dqn\u001b[39m.\u001b[39msave_weights(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdqn_\u001b[39m\u001b[39m{\u001b[39;00mENV_NAME\u001b[39m}\u001b[39;00m\u001b[39m_weights.h5f\u001b[39m\u001b[39m'\u001b[39m, overwrite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\rl\\core.py:168\u001b[0m, in \u001b[0;36mAgent.fit\u001b[1;34m(self, env, nb_steps, action_repetition, callbacks, verbose, visualize, nb_max_start_steps, start_step_policy, log_interval, nb_max_episode_steps)\u001b[0m\n\u001b[0;32m    165\u001b[0m callbacks\u001b[39m.\u001b[39mon_step_begin(episode_step)\n\u001b[0;32m    166\u001b[0m \u001b[39m# This is were all of the work happens. We first perceive and compute the action\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39m# (forward step) and then use the reward to improve (backward step).\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(observation)\n\u001b[0;32m    169\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessor\u001b[39m.\u001b[39mprocess_action(action)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\rl\\agents\\dqn.py:224\u001b[0m, in \u001b[0;36mDQNAgent.forward\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, observation):\n\u001b[0;32m    222\u001b[0m     \u001b[39m# Select an action.\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory\u001b[39m.\u001b[39mget_recent_state(observation)\n\u001b[1;32m--> 224\u001b[0m     q_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_q_values(state)\n\u001b[0;32m    225\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[0;32m    226\u001b[0m         action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy\u001b[39m.\u001b[39mselect_action(q_values\u001b[39m=\u001b[39mq_values)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\rl\\agents\\dqn.py:68\u001b[0m, in \u001b[0;36mAbstractDQNAgent.compute_q_values\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_q_values\u001b[39m(\u001b[39mself\u001b[39m, state):\n\u001b[1;32m---> 68\u001b[0m     q_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_batch_q_values([state])\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m     69\u001b[0m     \u001b[39massert\u001b[39;00m q_values\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnb_actions,)\n\u001b[0;32m     70\u001b[0m     \u001b[39mreturn\u001b[39;00m q_values\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\rl\\agents\\dqn.py:63\u001b[0m, in \u001b[0;36mAbstractDQNAgent.compute_batch_q_values\u001b[1;34m(self, state_batch)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_batch_q_values\u001b[39m(\u001b[39mself\u001b[39m, state_batch):\n\u001b[0;32m     62\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_state_batch(state_batch)\n\u001b[1;32m---> 63\u001b[0m     q_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict_on_batch(batch)\n\u001b[0;32m     64\u001b[0m     \u001b[39massert\u001b[39;00m q_values\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39mlen\u001b[39m(state_batch), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnb_actions)\n\u001b[0;32m     65\u001b[0m     \u001b[39mreturn\u001b[39;00m q_values\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\keras\\engine\\training_v1.py:1303\u001b[0m, in \u001b[0;36mModel.predict_on_batch\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   1298\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m   1299\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`predict_on_batch` is not supported for models distributed \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1300\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwith tf.distribute.Strategy.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1301\u001b[0m     )\n\u001b[0;32m   1302\u001b[0m \u001b[39m# Validate and standardize user data.\u001b[39;00m\n\u001b[1;32m-> 1303\u001b[0m inputs, _, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_standardize_user_data(\n\u001b[0;32m   1304\u001b[0m     x, extract_tensors_from_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m   1305\u001b[0m )\n\u001b[0;32m   1306\u001b[0m \u001b[39m# If `self._distribution_strategy` is True, then we are in a replica\u001b[39;00m\n\u001b[0;32m   1307\u001b[0m \u001b[39m# context at this point.\u001b[39;00m\n\u001b[0;32m   1308\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_eagerly \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_distribution_strategy:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\keras\\engine\\training_v1.py:2650\u001b[0m, in \u001b[0;36mModel._standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2641\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   2642\u001b[0m     \u001b[39mnot\u001b[39;00m run_eagerly\n\u001b[0;32m   2643\u001b[0m     \u001b[39mand\u001b[39;00m is_build_called\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2646\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(_is_symbolic_tensor(v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m all_inputs)\n\u001b[0;32m   2647\u001b[0m ):\n\u001b[0;32m   2648\u001b[0m     \u001b[39mreturn\u001b[39;00m [], [], \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2650\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_standardize_tensors(\n\u001b[0;32m   2651\u001b[0m     x,\n\u001b[0;32m   2652\u001b[0m     y,\n\u001b[0;32m   2653\u001b[0m     sample_weight,\n\u001b[0;32m   2654\u001b[0m     run_eagerly\u001b[39m=\u001b[39;49mrun_eagerly,\n\u001b[0;32m   2655\u001b[0m     dict_inputs\u001b[39m=\u001b[39;49mdict_inputs,\n\u001b[0;32m   2656\u001b[0m     is_dataset\u001b[39m=\u001b[39;49mis_dataset,\n\u001b[0;32m   2657\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m   2658\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   2659\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\keras\\engine\\training_v1.py:2691\u001b[0m, in \u001b[0;36mModel._standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2688\u001b[0m \u001b[39m# Standardize the inputs.\u001b[39;00m\n\u001b[0;32m   2689\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(x, (tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset, tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset)):\n\u001b[0;32m   2690\u001b[0m     \u001b[39m# TODO(fchollet): run static checks with dataset output shape(s).\u001b[39;00m\n\u001b[1;32m-> 2691\u001b[0m     x \u001b[39m=\u001b[39m training_utils_v1\u001b[39m.\u001b[39;49mstandardize_input_data(\n\u001b[0;32m   2692\u001b[0m         x,\n\u001b[0;32m   2693\u001b[0m         feed_input_names,\n\u001b[0;32m   2694\u001b[0m         feed_input_shapes,\n\u001b[0;32m   2695\u001b[0m         check_batch_axis\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,  \u001b[39m# Don't enforce the batch size.\u001b[39;49;00m\n\u001b[0;32m   2696\u001b[0m         exception_prefix\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39minput\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   2697\u001b[0m     )\n\u001b[0;32m   2699\u001b[0m \u001b[39m# Get typespecs for the input data and sanitize it if necessary.\u001b[39;00m\n\u001b[0;32m   2700\u001b[0m \u001b[39m# TODO(momernick): This should be capable of doing full input validation\u001b[39;00m\n\u001b[0;32m   2701\u001b[0m \u001b[39m# at all times - validate that this is so and refactor the\u001b[39;00m\n\u001b[0;32m   2702\u001b[0m \u001b[39m# standardization code.\u001b[39;00m\n\u001b[0;32m   2703\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset):\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\keras\\engine\\training_utils_v1.py:731\u001b[0m, in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[39mfor\u001b[39;00m dim, ref_dim \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(data_shape, shape):\n\u001b[0;32m    726\u001b[0m                 \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    727\u001b[0m                     ref_dim \u001b[39m!=\u001b[39m dim\n\u001b[0;32m    728\u001b[0m                     \u001b[39mand\u001b[39;00m ref_dim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    729\u001b[0m                     \u001b[39mand\u001b[39;00m dim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    730\u001b[0m                 ):\n\u001b[1;32m--> 731\u001b[0m                     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    732\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mError when checking \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    733\u001b[0m                         \u001b[39m+\u001b[39m exception_prefix\n\u001b[0;32m    734\u001b[0m                         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m: expected \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    735\u001b[0m                         \u001b[39m+\u001b[39m names[i]\n\u001b[0;32m    736\u001b[0m                         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m to have shape \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    737\u001b[0m                         \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(shape)\n\u001b[0;32m    738\u001b[0m                         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m but got array with shape \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    739\u001b[0m                         \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(data_shape)\n\u001b[0;32m    740\u001b[0m                     )\n\u001b[0;32m    741\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected flatten_1_input to have shape (1, 4) but got array with shape (1, 2)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "\n",
    "\n",
    "ENV_NAME = 'CartPole-v0'\n",
    "\n",
    "\n",
    "# Get the environment and extract the number of actions.\n",
    "env = gym.make(ENV_NAME)\n",
    "np.random.seed(123)\n",
    "nb_actions = env.action_space.n\n",
    "\n",
    "# Next, we build a very simple model.\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('linear'))\n",
    "print(model.summary())\n",
    "\n",
    "# Finally, we configure and compile our agent. You can use every built-in tensorflow.keras optimizer and\n",
    "# even the metrics!\n",
    "memory = SequentialMemory(limit=50000, window_length=1)\n",
    "policy = BoltzmannQPolicy()\n",
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=10,\n",
    "               target_model_update=1e-2, policy=policy)\n",
    "dqn.compile(Adam(learning_rate=1e-3), metrics=['mae'])\n",
    "\n",
    "# Okay, now it's time to learn something! We visualize the training here for show, but this\n",
    "# slows down training quite a lot. You can always safely abort the training prematurely using\n",
    "# Ctrl + C.\n",
    "dqn.fit(env, nb_steps=50000, visualize=True, verbose=2)\n",
    "\n",
    "# After training is done, we save the final weights.\n",
    "dqn.save_weights(f'dqn_{ENV_NAME}_weights.h5f', overwrite=True)\n",
    "\n",
    "# Finally, evaluate our algorithm for 5 episodes.\n",
    "dqn.test(env, nb_episodes=5, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "policy = BoltzmannQPolicy()\n",
    "memory = SequentialMemory(limit=50000, window_length=1)\n",
    "policy = BoltzmannQPolicy()\n",
    "dqn = DQNAgent(model=model, nb_actions=actions, memory=memory, nb_steps_warmup=10,\n",
    "               target_model_update=1e-2, policy=policy)\n",
    "Adam._name = 'hey'\n",
    "dqn.compile(Adam(learning_rate=1e-3), metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 50000 steps ...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected flatten_input to have shape (1, 4) but got array with shape (1, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dqn\u001b[39m.\u001b[39;49mfit(env, nb_steps\u001b[39m=\u001b[39;49m\u001b[39m50000\u001b[39;49m, visualize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\rl\\core.py:168\u001b[0m, in \u001b[0;36mAgent.fit\u001b[1;34m(self, env, nb_steps, action_repetition, callbacks, verbose, visualize, nb_max_start_steps, start_step_policy, log_interval, nb_max_episode_steps)\u001b[0m\n\u001b[0;32m    165\u001b[0m callbacks\u001b[39m.\u001b[39mon_step_begin(episode_step)\n\u001b[0;32m    166\u001b[0m \u001b[39m# This is were all of the work happens. We first perceive and compute the action\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39m# (forward step) and then use the reward to improve (backward step).\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(observation)\n\u001b[0;32m    169\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessor\u001b[39m.\u001b[39mprocess_action(action)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\rl\\agents\\dqn.py:224\u001b[0m, in \u001b[0;36mDQNAgent.forward\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, observation):\n\u001b[0;32m    222\u001b[0m     \u001b[39m# Select an action.\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory\u001b[39m.\u001b[39mget_recent_state(observation)\n\u001b[1;32m--> 224\u001b[0m     q_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_q_values(state)\n\u001b[0;32m    225\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[0;32m    226\u001b[0m         action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy\u001b[39m.\u001b[39mselect_action(q_values\u001b[39m=\u001b[39mq_values)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\rl\\agents\\dqn.py:68\u001b[0m, in \u001b[0;36mAbstractDQNAgent.compute_q_values\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_q_values\u001b[39m(\u001b[39mself\u001b[39m, state):\n\u001b[1;32m---> 68\u001b[0m     q_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_batch_q_values([state])\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m     69\u001b[0m     \u001b[39massert\u001b[39;00m q_values\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnb_actions,)\n\u001b[0;32m     70\u001b[0m     \u001b[39mreturn\u001b[39;00m q_values\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\rl\\agents\\dqn.py:63\u001b[0m, in \u001b[0;36mAbstractDQNAgent.compute_batch_q_values\u001b[1;34m(self, state_batch)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_batch_q_values\u001b[39m(\u001b[39mself\u001b[39m, state_batch):\n\u001b[0;32m     62\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_state_batch(state_batch)\n\u001b[1;32m---> 63\u001b[0m     q_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict_on_batch(batch)\n\u001b[0;32m     64\u001b[0m     \u001b[39massert\u001b[39;00m q_values\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39mlen\u001b[39m(state_batch), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnb_actions)\n\u001b[0;32m     65\u001b[0m     \u001b[39mreturn\u001b[39;00m q_values\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\keras\\engine\\training_v1.py:1303\u001b[0m, in \u001b[0;36mModel.predict_on_batch\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   1298\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m   1299\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`predict_on_batch` is not supported for models distributed \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1300\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwith tf.distribute.Strategy.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1301\u001b[0m     )\n\u001b[0;32m   1302\u001b[0m \u001b[39m# Validate and standardize user data.\u001b[39;00m\n\u001b[1;32m-> 1303\u001b[0m inputs, _, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_standardize_user_data(\n\u001b[0;32m   1304\u001b[0m     x, extract_tensors_from_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m   1305\u001b[0m )\n\u001b[0;32m   1306\u001b[0m \u001b[39m# If `self._distribution_strategy` is True, then we are in a replica\u001b[39;00m\n\u001b[0;32m   1307\u001b[0m \u001b[39m# context at this point.\u001b[39;00m\n\u001b[0;32m   1308\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_eagerly \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_distribution_strategy:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\keras\\engine\\training_v1.py:2650\u001b[0m, in \u001b[0;36mModel._standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2641\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   2642\u001b[0m     \u001b[39mnot\u001b[39;00m run_eagerly\n\u001b[0;32m   2643\u001b[0m     \u001b[39mand\u001b[39;00m is_build_called\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2646\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(_is_symbolic_tensor(v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m all_inputs)\n\u001b[0;32m   2647\u001b[0m ):\n\u001b[0;32m   2648\u001b[0m     \u001b[39mreturn\u001b[39;00m [], [], \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2650\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_standardize_tensors(\n\u001b[0;32m   2651\u001b[0m     x,\n\u001b[0;32m   2652\u001b[0m     y,\n\u001b[0;32m   2653\u001b[0m     sample_weight,\n\u001b[0;32m   2654\u001b[0m     run_eagerly\u001b[39m=\u001b[39;49mrun_eagerly,\n\u001b[0;32m   2655\u001b[0m     dict_inputs\u001b[39m=\u001b[39;49mdict_inputs,\n\u001b[0;32m   2656\u001b[0m     is_dataset\u001b[39m=\u001b[39;49mis_dataset,\n\u001b[0;32m   2657\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m   2658\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   2659\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\keras\\engine\\training_v1.py:2691\u001b[0m, in \u001b[0;36mModel._standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2688\u001b[0m \u001b[39m# Standardize the inputs.\u001b[39;00m\n\u001b[0;32m   2689\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(x, (tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset, tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset)):\n\u001b[0;32m   2690\u001b[0m     \u001b[39m# TODO(fchollet): run static checks with dataset output shape(s).\u001b[39;00m\n\u001b[1;32m-> 2691\u001b[0m     x \u001b[39m=\u001b[39m training_utils_v1\u001b[39m.\u001b[39;49mstandardize_input_data(\n\u001b[0;32m   2692\u001b[0m         x,\n\u001b[0;32m   2693\u001b[0m         feed_input_names,\n\u001b[0;32m   2694\u001b[0m         feed_input_shapes,\n\u001b[0;32m   2695\u001b[0m         check_batch_axis\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,  \u001b[39m# Don't enforce the batch size.\u001b[39;49;00m\n\u001b[0;32m   2696\u001b[0m         exception_prefix\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39minput\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   2697\u001b[0m     )\n\u001b[0;32m   2699\u001b[0m \u001b[39m# Get typespecs for the input data and sanitize it if necessary.\u001b[39;00m\n\u001b[0;32m   2700\u001b[0m \u001b[39m# TODO(momernick): This should be capable of doing full input validation\u001b[39;00m\n\u001b[0;32m   2701\u001b[0m \u001b[39m# at all times - validate that this is so and refactor the\u001b[39;00m\n\u001b[0;32m   2702\u001b[0m \u001b[39m# standardization code.\u001b[39;00m\n\u001b[0;32m   2703\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset):\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\keras\\engine\\training_utils_v1.py:731\u001b[0m, in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[39mfor\u001b[39;00m dim, ref_dim \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(data_shape, shape):\n\u001b[0;32m    726\u001b[0m                 \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    727\u001b[0m                     ref_dim \u001b[39m!=\u001b[39m dim\n\u001b[0;32m    728\u001b[0m                     \u001b[39mand\u001b[39;00m ref_dim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    729\u001b[0m                     \u001b[39mand\u001b[39;00m dim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    730\u001b[0m                 ):\n\u001b[1;32m--> 731\u001b[0m                     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    732\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mError when checking \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    733\u001b[0m                         \u001b[39m+\u001b[39m exception_prefix\n\u001b[0;32m    734\u001b[0m                         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m: expected \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    735\u001b[0m                         \u001b[39m+\u001b[39m names[i]\n\u001b[0;32m    736\u001b[0m                         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m to have shape \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    737\u001b[0m                         \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(shape)\n\u001b[0;32m    738\u001b[0m                         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m but got array with shape \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    739\u001b[0m                         \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(data_shape)\n\u001b[0;32m    740\u001b[0m                     )\n\u001b[0;32m    741\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected flatten_input to have shape (1, 4) but got array with shape (1, 2)"
     ]
    }
   ],
   "source": [
    "dqn.fit(env, nb_steps=50000, visualize=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent(model, actions):\n",
    "    policy = BoltzmannQPolicy()\n",
    "    memory = SequentialMemory(limit=50000, window_length=1)\n",
    "    dqn = DQNAgent(model=model, memory=memory, policy=policy,\n",
    "                    nb_actions=actions, nb_steps_warmup=10, target_model_update=1e-2)\n",
    "    return dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Keras symbolic inputs/outputs do not implement `__len__`. You may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model. This error will also get raised if you try asserting a symbolic input/output directly.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dqn \u001b[39m=\u001b[39m build_agent(model, actions)\n\u001b[0;32m      2\u001b[0m dqn\u001b[39m.\u001b[39mcompile(Adam(lr\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m), metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m dqn\u001b[39m.\u001b[39mfit(env, nb_steps\u001b[39m=\u001b[39m\u001b[39m50000\u001b[39m, visualize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[29], line 4\u001b[0m, in \u001b[0;36mbuild_agent\u001b[1;34m(model, actions)\u001b[0m\n\u001b[0;32m      2\u001b[0m policy \u001b[39m=\u001b[39m BoltzmannQPolicy()\n\u001b[0;32m      3\u001b[0m memory \u001b[39m=\u001b[39m SequentialMemory(limit\u001b[39m=\u001b[39m\u001b[39m50000\u001b[39m, window_length\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m dqn \u001b[39m=\u001b[39m DQNAgent(model\u001b[39m=\u001b[39;49mmodel, memory\u001b[39m=\u001b[39;49mmemory, policy\u001b[39m=\u001b[39;49mpolicy,\n\u001b[0;32m      5\u001b[0m                 nb_actions\u001b[39m=\u001b[39;49mactions, nb_steps_warmup\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, target_model_update\u001b[39m=\u001b[39;49m\u001b[39m1e-2\u001b[39;49m)\n\u001b[0;32m      6\u001b[0m \u001b[39mreturn\u001b[39;00m dqn\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\rl\\agents\\dqn.py:108\u001b[0m, in \u001b[0;36mDQNAgent.__init__\u001b[1;34m(self, model, policy, test_policy, enable_double_dqn, enable_dueling_network, dueling_type, *args, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39msuper\u001b[39m(DQNAgent, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    107\u001b[0m \u001b[39m# Validate (important) input.\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(model\u001b[39m.\u001b[39moutput, \u001b[39m'\u001b[39m\u001b[39m__len__\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39;49m(model\u001b[39m.\u001b[39;49moutput) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    109\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mModel \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m has more than one output. DQN expects a model that has a single output.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(model))\n\u001b[0;32m    110\u001b[0m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39moutput\u001b[39m.\u001b[39m_keras_shape \u001b[39m!=\u001b[39m (\u001b[39mNone\u001b[39;00m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnb_actions):\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\keras\\engine\\keras_tensor.py:244\u001b[0m, in \u001b[0;36mKerasTensor.__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__len__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 244\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    245\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mKeras symbolic inputs/outputs do not \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mimplement `__len__`. You may be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    247\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtrying to pass Keras symbolic inputs/outputs \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mto a TF API that does not register dispatching, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    249\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpreventing Keras from automatically \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mconverting the API call to a lambda layer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    251\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39min the Functional Model. This error will also get raised \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    252\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mif you try asserting a symbolic input/output directly.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: Keras symbolic inputs/outputs do not implement `__len__`. You may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model. This error will also get raised if you try asserting a symbolic input/output directly."
     ]
    }
   ],
   "source": [
    "dqn = build_agent(model, actions)\n",
    "dqn.compile(Adam(lr=1e-3), metrics=['mse'])\n",
    "dqn.fit(env, nb_steps=50000, visualize=True, verbose=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reloading RL Model "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
